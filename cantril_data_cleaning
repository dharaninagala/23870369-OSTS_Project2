#Author: Dharani Kumari Nagali
#Student Id: 23870369

#!/usr/bin/env bash

#Check if three files are provided as input
if [ "$#" -ne 3 ]; then
   echo "Usage: $0 <file1.tsv> <file2.tsv> <file3.tsv>"
   exit 1
fi

#Function to check whether given file is a tsv file or not
check_tsv_file()
{
    local file="$1";
    awk -F'\t' 'NR==1 {
    if (NF > 1) 
    {
        exit 0;  
    } else 
    {
        exit 1;  
    }
    }' "$file"

    if [ $? -ne 0 ]; 
    then
        echo "The input file $file is not a tsv file";
        exit 1;
    fi
}

#Function to remove continent column in the file 
remove_continent_column() 
{
    local file="$1"
    awk 'BEGIN { FS = "\t"; OFS = "\t" } { NF--; print }' "$file";
}

# Function to filter rows based on year and country code
filter_rows() {
    local min_year=2011
    local max_year=2021
    awk -v min="$min_year" -v max="$max_year" -F "\t" '$3 >= min && $3 <= max && $2 != ""';
}
 

# Function remove_inconsistent_lines() is used to ignore the rows that doesn't match with header count
remove_inconsistent_lines() {
    local file="$1"
    local clean_file="clean_$file"
    head -n 1 "$file" > "$clean_file"

    # Read the number of fields expected from the header
    local num_fields=$(head -n 1 "$file" | awk -F '\t' '{print NF}')
    # Check each subsequent line to ensure it has the correct number of fields
    # Report errors to stderr and do not print lines with incorrect field count
    awk -F '\t' -v num_fields="$num_fields" 'NR > 1 {
        if (NF != num_fields)
        {
            print "Error: Line " NR " in file '"$file"' has a different number of cells than the header" > "/dev/null"
        }
        else 
        {
            print $0 >> "'"$clean_file"'" 
        }
    }' "$file"
    if [ -s "$clean_file" ]; then  # Check if clean file has size greater than zero
        mv "$clean_file" "$file"
    fi
}


# Iterating over the files passed in the command line
for file in "$@"; 
do
    check_tsv_file "$file";
    remove_inconsistent_lines "$file";
    #Storing the header of each file in a variable
    header=$(head -n 1 "$file")
    #Comparing the header of the file with Homicide columns
    if [[ "$header" == $'Entity\tCode\tYear\t'*'Homicide rate per 100,000 population - Both sexes - All ages'* ]]; 
    then
        filter_rows < "$file" | sort -k2,2 -k3,3n > "homicide.tsv"
    
    #Comparing the header of the file with GDP columns
    elif [[ "$header" == $'Entity\tCode\tYear\tCantril ladder score\t\"GDP per capita, PPP (constant 2017 international $)\"\tPopulation (historical estimates)\tContinent' ]]; 
    then
        remove_continent_column "$file" | filter_rows | sort -k2,2 -k3,3n > "gdp.tsv"
    #Comparing the header of the file with Life columns
    elif [[ "$header" == $'Entity\tCode\tYear\tLife expectancy - Sex: all - Age: at birth - Variant: estimates\tCantril ladder score\tPopulation (historical estimates)\tContinent' ]];
    then 
        remove_continent_column "$file" | filter_rows | sort -k2,2 -k3,3n > "life.tsv"
    fi
done

# Output file
output_file="merged_file.tsv"

#Storing header columns in the output file
echo $'Entity/Country\tCode\tYear\tGDP per capita\tPopulation\tHomicide Rate\tLife Expectancy\tCantril Ladder score' > $output_file

# Remove extra spaces, ensure Unix line endings, and prepare files by concatenating key fields and sorting
awk -F'\t' -v OFS='\t' '{gsub(/\r/, ""); print $2 "-" $3, $0}' "homicide.tsv" | sort -k1,1 > temp_homicide.tsv
awk -F'\t' -v OFS='\t' '{gsub(/\r/, ""); print $2 "-" $3, $0}' "gdp.tsv" | sort -k1,1 > temp_gdp.tsv
awk -F'\t' -v OFS='\t' '{gsub(/\r/, ""); print $2 "-" $3, $0}' "life.tsv" | sort -k1,1 > temp_life.tsv 


# Perform the first join on the key between  cleaned Homicide and GDP  files
join -t $'\t' -j 1 -o '0,1.2,1.3,1.4,1.5,2.5,2.6,2.7' temp_homicide.tsv temp_gdp.tsv > temp_join1.tsv
# Perform the second join on the key between the first join result and cleaned life expectancy file
join -t $'\t' -j 1 -o '1.2,1.3,1.4,1.7,1.8,1.5,2.5,1.6' temp_join1.tsv temp_life.tsv >> $output_file

#Removing the temporary files created throught out the program
rm temp_homicide.tsv temp_gdp.tsv temp_join1.tsv temp_life.tsv homicide.tsv gdp.tsv life.tsv;